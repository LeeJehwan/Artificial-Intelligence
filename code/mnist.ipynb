{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SOURCE_URL = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "FILENAME = SOURCE_URL.split('/')[-1]\n",
    "DATA_DIR = './datasets'\n",
    "\n",
    "def maybe_download(data_dir):\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    if not os.path.isfile(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading {} {:.1f} %'.format(\n",
    "                FILENAME, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully donloaded', FILENAME, statinfo.st_size, 'bytes.')\n",
    "\n",
    "def load(data_dir, subset='train'):\n",
    "    maybe_download(data_dir)\n",
    "    filepath = os.path.join(data_dir, FILENAME)\n",
    "    \n",
    "    f = gzip.open(filepath, 'rb')\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    train_set, valid_set, test_set = u.load()\n",
    "    f.close()\n",
    "    \n",
    "    if subset == 'train':\n",
    "        trainx, trainy = train_set\n",
    "        trainx = trainx.astype(np.float32).reshape(trainx.shape[0], 28, 28)\n",
    "        trainy = trainy.astype(np.uint8)\n",
    "        return trainx, trainy\n",
    "    elif subset == 'test':\n",
    "        testx, testy = test_set\n",
    "        testx = testx.astype(np.float32).reshape(testx.shape[0], 28, 28)\n",
    "        testy = testy.astype(np.uint8)\n",
    "        return testx, testy\n",
    "    elif subset== 'valid':\n",
    "        validx, validy = valid_set\n",
    "        validx = validx.astype(np.float32).reshape(validx.shape[0], 28, 28)\n",
    "        validy = validy.astype(np.uint8)\n",
    "        return validx, validy\n",
    "    else:\n",
    "        raise NotImplementedError('subset should be train or valid or test')\n",
    "\n",
    "# Load data\n",
    "train_data, train_label = load(DATA_DIR, 'train')\n",
    "valid_data, valid_label = load(DATA_DIR, 'valid')\n",
    "test_data, test_label = load(DATA_DIR, 'test')\n",
    "\n",
    "# concatenate train and valid data as train data\n",
    "train_data = np.concatenate((train_data, valid_data))\n",
    "train_label = np.concatenate((train_label, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 확인 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[0]\n",
    "ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, by):\n",
    "    X = tf.expand_dims(X, axis = 3)\n",
    "    with tf.variable_scope('first'):\n",
    "        outs = tf.layers.conv2d(X, 128, 3, padding = 'same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2)\n",
    "    with tf.variable_scope('second'):\n",
    "        outs = tf.layers.conv2d(outs, 256, 3, padding = 'same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2)\n",
    "    with tf.variable_scope('third'):\n",
    "        outs = tf.layers.conv2d(outs, 128, 3, padding = 'same')\n",
    "        outs = tf.nn.relu(outs)\n",
    "        outs = tf.layers.max_pooling2d(outs, 2, 2)\n",
    "    outs = tf.reshape(outs, \n",
    "                      (-1, outs.shape[1] * outs.shape[2] * outs.shape[3]))\n",
    "    outs = tf.layers.dense(outs, 256)\n",
    "    outs = tf.nn.relu(outs)\n",
    "    outs = tf.layers.dense(outs, 10)\n",
    "    \n",
    "    one_hot = tf.one_hot(by, 10)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2 (labels = one_hot, logits = outs)\n",
    "    \n",
    "    loss = tf.reduce_mean(loss)\n",
    "    opt = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "    \n",
    "    preds = tf.cast(tf.argmax(tf.nn.softmax(outs), axis=1), tf.int32)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(by, preds), tf.float32))\n",
    "    return {\n",
    "        'loss':loss,\n",
    "        'opt':opt,\n",
    "        'preds': preds,\n",
    "        'acc': acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 28, 28))\n",
    "by = tf.placeholder(tf.int32)\n",
    "\n",
    "ours = model(X, by)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 100\n",
    "num_display = 100\n",
    "num_samples = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 2.3159 acc 0.0700 \n",
      "loss 0.1665 acc 0.9200 \n",
      "loss 0.1107 acc 0.9400 \n",
      "loss 0.0591 acc 0.9900 \n",
      "loss 0.0391 acc 0.9900 \n",
      "loss 0.0287 acc 0.9900 \n",
      "train finished\n",
      "test start\n",
      "Test acc 0.9876 \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess. run(init)\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "        for ind_ in range(0, int(num_samples / batch_size)):\n",
    "            batch_X = train_data[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = train_label[ind_*batch_size:(ind_+1)*batch_size]\n",
    "\n",
    "            _, cur_loss, cur_acc = sess.run([ours['opt'], ours['loss'], ours['acc']],\n",
    "                    feed_dict = {X: batch_X , by : batch_by})\n",
    "            if ind_ % num_display == 0:\n",
    "                print(\"loss {0:.4f} acc {1:.4f} \".format(cur_loss, cur_acc))\n",
    "\n",
    "    print(\"train finished\")\n",
    "    print(\"test start\")    \n",
    "\n",
    "    N = test_data.shape[0]\n",
    "    test_acc = 0\n",
    "\n",
    "    for ind_ in range(0, int(N / batch_size)):\n",
    "        test_batch_X = test_data[ind_*batch_size:(ind_+1)*batch_size]\n",
    "        test_batch_by = test_label[ind_*batch_size:(ind_+1)*batch_size]\n",
    "        test_acc += sess.run(ours['acc'], \n",
    "                             feed_dict = {X: test_batch_X , by : test_batch_by}) * test_batch_X.shape[0]\n",
    "    test_acc = test_acc / N\n",
    "    print(\"Test acc {0:.4f} \".format(test_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-5-a50f363886f0>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](first/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_25}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'first/conv2d/Conv2D', defined at:\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-aeadf33f0217>\", line 4, in <module>\n    ours = model(X, by)\n  File \"<ipython-input-5-a50f363886f0>\", line 4, in model\n    outs = tf.layers.conv2d(X, 128, 3, padding = 'same')\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 417, in conv2d\n    return layer.apply(inputs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-5-a50f363886f0>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](first/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_25}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node first/conv2d/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](first/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_25}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6279c9921586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m cur_acc = sess.run([ours['acc']],\n\u001b[0;32m----> 2\u001b[0;31m                 feed_dict = {X: test_data , by : test_label})\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss {0:.4f} acc {1:.4f} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-5-a50f363886f0>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](first/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_25}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'first/conv2d/Conv2D', defined at:\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-aeadf33f0217>\", line 4, in <module>\n    ours = model(X, by)\n  File \"<ipython-input-5-a50f363886f0>\", line 4, in model\n    outs = tf.layers.conv2d(X, 128, 3, padding = 'same')\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 417, in conv2d\n    return layer.apply(inputs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 817, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/pirl/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,128,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node first/conv2d/Conv2D (defined at <ipython-input-5-a50f363886f0>:4)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](first/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, first/conv2d/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_1/_25}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "cur_acc = sess.run([ours['acc']],\n",
    "                feed_dict = {X: test_data , by : test_label})\n",
    "print(\"loss {0:.4f} acc {1:.4f} \".format(cur_loss, cur_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_sample, y_sample, batch_size=512):\n",
    "    \"\"\"Run a minibatch accuracy op\"\"\"\n",
    "    \n",
    "    N = X_sample.shape[0]\n",
    "    correct_sample = 0\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_sample[i: i + batch_size]\n",
    "        y_batch = y_sample[i: i + batch_size]\n",
    "        N_batch = X_batch.shape[0]\n",
    "\n",
    "        feed = {\n",
    "            X: X_batch,\n",
    "            by: y_batch\n",
    "        }\n",
    "\n",
    "        correct_sample += sess.run(ours['acc'], feed_dict=feed) * N_batch\n",
    "\n",
    "    return correct_sample / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857999995231629"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
