{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GAN.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 1174s 7us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(train_data, train_label), (test_data, test_label) = cifar10.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    ''' Tile images in a grid.\n",
    "    If tile_shape is provided only as many images as specified in tile_shape\n",
    "    will be included in the output.\n",
    "    '''\n",
    "\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "ax1.imshow(sample_data);\n",
    "# ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './gan_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of input feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        fc: inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # in_channel: input channel dimension\n",
    "    # w_shape: shape of weight matrix\n",
    "    # b_shape: shape of bias vector\n",
    "    in_channel = inputs.get_shape().as_list()[1]\n",
    "    w_shape = [in_channel, out_channel]\n",
    "    b_shape = [out_channel]\n",
    "\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "        weights = tf.get_variable('weights', shape=w_shape,\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        biases = tf.get_variable('biases', shape=b_shape,\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        fc = tf.matmul(inputs, weights)\n",
    "        fc = tf.nn.bias_add(fc, biases)\n",
    "\n",
    "        return fc\n",
    "\n",
    "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"conv2d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "\n",
    "        return conv\n",
    "\n",
    "def bn(x, is_training, scope, axis=-1):\n",
    "    return tf.layers.batch_normalization(x, epsilon = 1e-5, momentum = 0.9, training = is_training, name = scope, axis=axis) # add axis=1\n",
    "\n",
    "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
    "    shape = input_.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
    "                 tf.random_normal_initializer(stddev=stddev))\n",
    "        bias = tf.get_variable(\"bias\", [output_size],\n",
    "        initializer=tf.constant_initializer(bias_start))\n",
    "        if with_w:\n",
    "            return tf.matmul(input_, matrix) + bias, matrix, bias\n",
    "        else:\n",
    "            return tf.matmul(input_, matrix) + bias\n",
    "\n",
    "def deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, name=\"deconv2d\", stddev=0.02, with_w=False):\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "        try:\n",
    "            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        # Support for verisons of TensorFlow before 0.7.0\n",
    "        except AttributeError:\n",
    "            deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "\n",
    "        if with_w:\n",
    "            return deconv, w, biases\n",
    "        else:\n",
    "            return deconv\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)\n",
    "        \n",
    "def discriminator(x, reuse=None, is_training=True):\n",
    "    \"\"\"\n",
    "    build the discriminator\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 32, 32, 3]\n",
    "\n",
    "    returns:\n",
    "        net: output of the discriminator [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "#             if self.dataset_name == 'cifar10':\n",
    "        if True:\n",
    "            print(\"D:\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            net = lrelu(conv2d(x, 64, 5, 5, 2, 2, name='d_conv1'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 128, 5, 5, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 256, 5, 5, 2, 2, name='d_conv3'), is_training=is_training, scope='d_bn3'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 512, 5, 5, 2, 2, name='d_conv4'), is_training=is_training, scope='d_bn4'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = tf.reshape(net, [batch_size, -1])\n",
    "            print(\"D:\",net.get_shape())\n",
    "            out_logit = linear(net, 1, scope='d_fc5')\n",
    "            print(\"D:\",net.get_shape())\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "        else: # mnist / fashion mnist\n",
    "            #print(x.get_shape())\n",
    "            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n",
    "            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            net = tf.reshape(net, [batch_size, -1])\n",
    "            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n",
    "            out_logit = linear(net, 1, scope='d_fc4')\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "\n",
    "        return out\n",
    "\n",
    "def generator(z, is_training=True):\n",
    "    \"\"\"\n",
    "    build the generator\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "\n",
    "        h_size = 32\n",
    "        h_size_2 = 16\n",
    "        h_size_4 = 8\n",
    "        h_size_8 = 4\n",
    "        h_size_16 = 2\n",
    "\n",
    "        print(\"G:\",z.get_shape())\n",
    "        net = linear(z, 512*h_size_16*h_size_16, scope='g_fc1')\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(tf.reshape(net, [batch_size, h_size_16, h_size_16, 512]),is_training=is_training, scope='g_bn1')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_8, h_size_8, 256], 5, 5, 2, 2, name='g_dc2'),is_training=is_training, scope='g_bn2')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_4, h_size_4, 128], 5, 5, 2, 2, name='g_dc3'),is_training=is_training, scope='g_bn3')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_2, h_size_2, 64], 5, 5, 2, 2, name='g_dc4'),is_training=is_training, scope='g_bn4')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        out = tf.nn.sigmoid(\n",
    "            deconv2d(net, [batch_size, 32, 32, 3], 5, 5, 2, 2, name='g_dc5')\n",
    "            )\n",
    "        print(\"G:\",out.get_shape())\n",
    "        print(\"------------------------\")\n",
    "    return out\n",
    "\n",
    "def get_loss(D_real, D_fake, eps=1e-10):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        D_real: Real Discriminator output [batch_size, 1]\n",
    "        D_fake: Fake discriminator output [batch_size, 1]\n",
    "\n",
    "    Returns:\n",
    "        D_loss: Discriminator loss\n",
    "        G_loss: Generator loss\n",
    "    \"\"\"\n",
    "    D_loss = -(tf.reduce_mean(tf.log(D_real+eps)) + tf.reduce_mean(tf.log(1-D_fake+eps)))\n",
    "    G_loss = -tf.reduce_mean(tf.log(D_fake+eps))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "\n",
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 128\n",
    "max_step = 20000\n",
    "lrD = 1e-3\n",
    "lrG = 1e-4\n",
    "beta1 = 0.5\n",
    "\n",
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = __________________________________________________\n",
    "# Define z vector as uniform distribution between [-1, 1]\n",
    "z = __________________________________________________\n",
    "\n",
    "# Build discriminator where input data is real image x\n",
    "______________________________________________________\n",
    "# Build generator\n",
    "______________________________________________________\n",
    "# Build discriminator where input data is generated image G\n",
    "______________________________________________________\n",
    "\n",
    "# Get D_loss and G_loss\n",
    "______________________________________________________\n",
    "\n",
    "# Make optimization op\n",
    "______________________________________________________\n",
    "______________________________________________________\n",
    "\n",
    "# To update the generator and the discriminator\n",
    "# get their network parameters\n",
    "______________________________________________________\n",
    "______________________________________________________\n",
    "\n",
    "# Make train op for each network\n",
    "D_train = ____________________________________________\n",
    "G_train = ____________________________________________\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled)\n",
    "    \n",
    "    samples = []\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        \n",
    "        _, d_loss = sess.run([D_train, D_loss], feed_dict={x: batch_x})\n",
    "        _, g_loss = sess.run([G_train, G_loss])\n",
    "        #summary = sess.run(merged, feed_dict={x: batch_x})\n",
    "        #train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            g = sess.run(G)\n",
    "            g_tiled = img_tile(g, border_color=1.0)\n",
    "            g_tiled = np.squeeze(g_tiled)\n",
    "            samples.append(g_tiled)\n",
    "        if step % 200 == 0:\n",
    "            print(\"{} steps |  G_loss: {:.4f}, D_loss: {:.4f}\".format(step, g_loss, d_loss))\n",
    "            plt.imshow(g_tiled)\n",
    "            plt.show()\n",
    "            plt.imsave(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)),\n",
    "                       g_tiled)\n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "https://github.com/4thgen/DCGAN-CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
