{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치\n",
    "##### window\n",
    "pip install scikit-image==0.14.2 --user <br />\n",
    "conda install numpy <br />\n",
    "pip install scikit-learn --user\n",
    "\n",
    "##### ubuntu\n",
    "conda install scikit-image==0.14.2 <br />\n",
    "conda install numpy <br />\n",
    "conda install scikit-learn\n",
    "\n",
    "##### home에 cifar10_data 폴더를 복사해 둘 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification using LBP and HOG features\n",
    "이번 실습에서는 CIFAR-10 dataset에서 LBP와 HOG feature를 추출하고 이를 Random Forest classification 학습과 성능을 살펴본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=missing-docstring\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# own python codes\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from utils import *\n",
    "from cifar10_loader import CIFAR10_loader\n",
    "\n",
    "from skimage import feature\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "        # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    " \n",
    "    def describe(self, image):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "                                           self.radius)\n",
    "        #flatten\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "                                 bins=16)\n",
    "        \n",
    "        # return the histogram of Local Binary Patterns\n",
    "        return hist, lbp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skimage.feature.local_binary_pattern(image, P, R, method)\n",
    "- image: (N, M) array\n",
    "- P: number of neighbors\n",
    "- R: number of radius\n",
    "(P = R * 8)\n",
    "- method: {'default', 'ror', 'uniform', 'var'}\n",
    "\n",
    "output: (N, M) array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the CIFAR-10 dataset\n",
    "**CIFAR-10** dataset은 32x32 사이즈의 이미지들로 airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck으로 이루어져있다. 각 클래스 별 6천장씩 구성되어 있으며 이중 50000장이 training에 사용되고 10000장이 test에 사용된다. TF-Slim library에서 제공하는 코드를 이용하여 현재 작업중인 폴더의 하위 폴더에 cifar-10 dataset을 저장한다.\n",
    "\n",
    "*CIFAR datasets URL*: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "*CIFAR-10 download link*: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading cifar-10-python.tar.gz 100.0%\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Extracting Finished\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../cifar10_data'\n",
    "data_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "maybe_download_and_extract(data_url, data_dir, 'cifar-10-batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loader and check the CIFAR-10 dataset\n",
    "위에서 다운받은 데이터를 batch 단위로 읽어올 수 있는 data loader class를 선언. 현재 data loader는 get_batch()를 통해 단순히 이미지 및 레이블을 batch 크기만큼 받아올 수 있으며, 여기서는 특별한 preprocessing을 하지는 않는다. 하지만 보통 더 높은 성능을 위해서 random crop, flipping 등의 preprocessing을 하는 편이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/pirl/github/Computer-Vision-example/cifar10_data/cifar-10-batches-py/data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6b5347b8cc58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Computer-Vision-example/edu_/cifar10_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m#with open(os.path.join(CUR_PATH, 'cifar-10-batches-py/data_batch_%d') % (i+1), 'r') as file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../cifar10_data/cifar-10-batches-py/data_batch_%d'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mloaded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/pirl/github/Computer-Vision-example/cifar10_data/cifar-10-batches-py/data_batch_1'"
     ]
    }
   ],
   "source": [
    "loader = CIFAR10_loader()\n",
    "class_names = loader.get_class_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5ab9bb52db3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "batch = loader.get_batch(9)\n",
    "fig = plot_images(batch['images'], batch['labels'], class_names)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 LBP의 points와 radius를 정의하고 각 training image에서 추출된 LBP, HOG, ground truth를 저장할 변수를 선언한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the local binary patterns descriptor along with\n",
    "# the data and label lists\n",
    "desc = LocalBinaryPatterns(8, 1) # num of points and radius\n",
    "\n",
    "train_lbp = []\n",
    "train_hog = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBP와 HOG feature를 추출하기 위해 gray scale로 image를 변환하고 scikit-image library에 정의된 함수를 이용하여 각 feature를 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pirl/anaconda3/envs/edu/lib/python3.6/site-packages/skimage/feature/_hog.py:150: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15. To supress this message specify explicitly the normalization method.\n",
      "  skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature gen: 0\n",
      "[205 132   8  67  34   4  16  55  49  17   2  24  80   3  98 230]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 1000\n",
      "[196 181   8  75  27   9  18  52  39  12   0  16  69  10 124 188]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 2000\n",
      "[312 222   5  68  20   7  15  71  34  16   3  25  36  10  49 131]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 3000\n",
      "[186 126   6  34  63   6  12  44  53  12   1  31  82   7 133 228]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 4000\n",
      "[138 120   3 141  25   0  13  95 113  11   1  19  87   4  79 175]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 5000\n",
      "[170  88   8  79  45   6  21 138  72   9   3  14  84   8  55 224]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 6000\n",
      "[209 136   9  57  24   2  22  52  63  12   4  12 100  10 108 204]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 7000\n",
      "[165  95   8 135  38   8  16 138  52  12   2  27  54  12  46 216]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 8000\n",
      "[204 167   8  67  20   3  18  74  39  11   2  17  72   9 115 198]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 9000\n",
      "[215 135   7  54  26   3  15  54  59  17   2  16  84  16 103 218]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 10000\n",
      "[138 145  11  41  41   4  26  57  26  20   1  17  66  20 149 262]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 11000\n",
      "[212 145   2  85  26   3  10 120  33  14   2  17  48   9 105 193]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 12000\n",
      "[198  87   5  63  38   4  18  85  53  18   5  21  93   7 113 216]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 13000\n",
      "[170 160   4  51  42   3  15  92  46  12   6  23  47   4 122 227]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 14000\n",
      "[190  82   5  76  53   7  18  95  95  21   4  34  99  12  55 178]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 15000\n",
      "[190 101   4  35  36   2  21  54  61  10   1   9 100  13 156 231]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 16000\n",
      "[221 112   7  60  29   8  23  72  44  19   5  34  98  11  80 201]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 17000\n",
      "[231  92   8  53  51   9  20  51  46  13   5  29  81  14  93 228]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 18000\n",
      "[190 146   6  76  24   2  19  62  51  18   5  20  57  17 132 199]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 19000\n",
      "[209 138  11  84  30   2  17 118  50  11   4  28  55   8  67 192]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 20000\n",
      "[183 113   8  97  32   7  21  82  30  15   2  33  87  15 107 192]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 21000\n",
      "[162 200   2  46  19   6   4 160  19  11   1   6  35   8  97 248]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 22000\n",
      "[171 167   8  70  34   6  19  44  28  19   1  13 116  21 122 185]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 23000\n",
      "[167 177   1  66  25   0  18  94  54  11   1  16  70   4  98 222]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 24000\n",
      "[224 153  12 102  29   5  21  63  31  17   5  23  47  13  74 205]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 25000\n",
      "[153  96   3  64  24   6  15  85  63   3   1  12 142   8 132 217]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 26000\n",
      "[246 192   5  61  19  10  21  60  29  23   0  10  72  12  93 171]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 27000\n",
      "[159 195   1  26   9   3   2  49  13   4   1   3  24   5  71 459]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 28000\n",
      "[221 357   2  21   9   4   6  26  10  14   0   7  27  10 114 196]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 29000\n",
      "[178 160   5  87  29   4  11  85  47  18   2  26  79   4  89 200]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 30000\n",
      "[236 223   4  55  19   7   8  60  38  21   3  21  37   8  85 199]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 31000\n",
      "[213 257   2  21  12   6   8  43  25  15   0   6  35  15  90 276]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 32000\n",
      "[204 166   4  66  19   4  19  65  62  18   2  30  73   7 119 166]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 33000\n",
      "[ 86  85   6  21  26   9  10 135  15   9   0   7 145  15  67 388]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 34000\n",
      "[184 132   3  70  53   7  13  87  95  18   1  28 120   7  66 140]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 35000\n",
      "[114  57   4  53  26   3  19  98  49   8   4  18 124   5 208 234]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 36000\n",
      "[185 126  10  81  32   2  22  78  32  13   0  10  69   6 122 236]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 37000\n",
      "[194  89   3  70  53   9  22  78  77  15   6  35 140  10  62 161]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 38000\n",
      "[145 154   4  65  14   4   7  98  48   5   0   9 135   4  92 240]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 39000\n",
      "[228 108   7  65  27   9  26  66  56  19   7  26  98   9  87 186]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 40000\n",
      "[225 179   4  70  42   9   7  68  55  10   3  29  49   9  83 182]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 41000\n",
      "[225 196   4  63  32   5  19  67  41  18   3  26  86   6  64 169]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 42000\n",
      "[210 172   3  94  45   5   7  58  57  19   2  29  53   9  78 183]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 43000\n",
      "[108  77   3  87  39   7  20 100  50   3   2  19 135   3 119 252]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 44000\n",
      "[203 150   0  49  17   3  13  61  21  18   5   8  60   7 117 292]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 45000\n",
      "[210  99   3  61  45   1  22  72  67  15   4  35  86  11  92 201]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 46000\n",
      "[209 124   8 106  31   4  14  82  49  15   1  19 105   9  77 171]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 47000\n",
      "[187 286   0 113  11   5   6  83  54  30   0  10  49   9  73 108]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 48000\n",
      "[148 191   7 110  33   5  20  71  23  10   1  21  73   9 102 200]\n",
      "144\n",
      "255.0\n",
      "0.0\n",
      "feature gen: 49000\n",
      "[218 176   1  45  41   1  12  54  40  14   1  14  90  18  87 212]\n",
      "144\n",
      "255.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# set iterator as 0\n",
    "loader.reset()\n",
    "\n",
    "for ii in range(50000):\n",
    "    # Load a batch data\n",
    "    batch = loader.get_batch(1, 'train')\n",
    "    \n",
    "    images = batch['images'].reshape(32,32,3) * 255\n",
    "    images = images.astype('uint8')\n",
    "    \n",
    "    gray = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fd = feature.hog(gray, orientations=9, pixels_per_cell=(8, 8), \n",
    "             cells_per_block=(4, 4))\n",
    "    \n",
    "    hist, lbp = desc.describe(gray)\n",
    "    if ii % 1000 == 0:\n",
    "        print(\"feature gen: %d\" % ii)\n",
    "        print(hist)\n",
    "        print(len(fd))\n",
    "        print(lbp.max())\n",
    "        print(lbp.min())\n",
    "    train_labels.append(batch['labels'])\n",
    "    train_lbp.append(hist)\n",
    "    train_hog.append(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier 선언\n",
    "scikit-learn library에 정의된 RandomForestClassifier()를 이용하여 선언한다. 이 함수에서 사용될 수 있는 인자는 아래 링크에 자세히 나와있으며 그 중 중요한 인자들은 아래와 같다.\n",
    "\n",
    "link: *http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier*\n",
    "\n",
    "\n",
    "- n_estimaters: number of trees\n",
    "- criterion: gini / entropy (impurity 계산 방식)\n",
    "- max_features: number of features to consider\n",
    "- max_depth\n",
    "- max_samples_split: number of children nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pirl/anaconda3/envs/edu/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/pirl/anaconda3/envs/edu/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(np.concatenate((train_lbp, train_hog), axis=1), train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testset data에서 추출한 lbp, hog feature와 ground truth label 정보를 저장할 변수를 선언한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature gen: 0\n",
      "16\n",
      "144\n",
      "feature gen: 1000\n",
      "16\n",
      "144\n",
      "feature gen: 2000\n",
      "16\n",
      "144\n",
      "feature gen: 3000\n",
      "16\n",
      "144\n",
      "feature gen: 4000\n",
      "16\n",
      "144\n",
      "feature gen: 5000\n",
      "16\n",
      "144\n",
      "feature gen: 6000\n",
      "16\n",
      "144\n",
      "feature gen: 7000\n",
      "16\n",
      "144\n",
      "feature gen: 8000\n",
      "16\n",
      "144\n",
      "feature gen: 9000\n",
      "16\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "loader.reset()\n",
    "\n",
    "test_lbp = []\n",
    "test_hog = []\n",
    "test_labels = []\n",
    "\n",
    "for ii in range(10000):\n",
    "    # Load a batch data\n",
    "    batch = loader.get_batch(1, 'test')\n",
    "    \n",
    "    images = batch['images'].reshape(32,32,3) * 255\n",
    "    images = images.astype('uint8')\n",
    "    \n",
    "    gray = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    fd = feature.hog(gray, orientations=9, pixels_per_cell=(8, 8), \n",
    "             cells_per_block=(4, 4))\n",
    "    \n",
    "    hist, lbp = desc.describe(gray)\n",
    "    if ii % 1000 == 0:\n",
    "        print(\"feature gen: %d\" % ii)\n",
    "        print(len(hist))\n",
    "        print(len(fd))\n",
    "    test_labels.append(batch['labels'])\n",
    "    test_lbp.append(hist)\n",
    "    test_hog.append(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 Random Forest Classifier에 testset의 feature vectors를 이용하여 classification을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Apply the Classifier we trained to the test data (which, remember, it has never seen before)\n",
    "pred_labels = []\n",
    "\n",
    "pred_labels = clf.predict(np.concatenate((test_lbp, test_hog), axis=1))\n",
    "\n",
    "print(len(pred_labels))\n",
    "print(len(test_labels))\n",
    "\n",
    "test_labels = [ int(x) for x in test_labels ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ground truth label과 predicted label를 이용하여 confusion matrix를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[537,  69,  82,  50,  30,  23,  12,  29, 146,  22],\n",
       "       [113, 523,  35,  35,  42,  20,  33,  19,  86,  94],\n",
       "       [119,  53, 265, 122, 100, 136,  95,  33,  42,  35],\n",
       "       [ 58,  72, 157, 244, 107, 160,  85,  54,  23,  40],\n",
       "       [ 46,  67, 117, 116, 304,  76, 126,  90,  24,  34],\n",
       "       [ 37,  59, 153, 213,  86, 300,  58,  63,  12,  19],\n",
       "       [ 45,  67,  93,  85, 130,  72, 441,  34,  14,  19],\n",
       "       [ 54,  75, 110, 111, 105, 104,  50, 314,  18,  59],\n",
       "       [206, 174,  40,  34,  25,   9,   9,  23, 414,  66],\n",
       "       [107, 196,  40,  60,  56,  34,  23,  68,  79, 337]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "confusion_matrix(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy를 측정한다.\n",
    "\n",
    "- true positive (TP): number of hit\n",
    "- true negative (TN): number of correct rejection\n",
    "- false positive (FP): number of false hit\n",
    "- false negative (FN): number of false miss\n",
    "\n",
    "\n",
    "- precision: TP / (TP + FP)\n",
    "- recall: TP / (TP + FN)\n",
    "- f1-score (harmonic mean of precision and recall): 1/precision + 1/recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.54      0.46      1000\n",
      "           1       0.39      0.52      0.44      1000\n",
      "           2       0.24      0.27      0.25      1000\n",
      "           3       0.23      0.24      0.24      1000\n",
      "           4       0.31      0.30      0.31      1000\n",
      "           5       0.32      0.30      0.31      1000\n",
      "           6       0.47      0.44      0.46      1000\n",
      "           7       0.43      0.31      0.36      1000\n",
      "           8       0.48      0.41      0.45      1000\n",
      "           9       0.46      0.34      0.39      1000\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     10000\n",
      "   macro avg       0.37      0.37      0.37     10000\n",
      "weighted avg       0.37      0.37      0.37     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu",
   "language": "python",
   "name": "edu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
